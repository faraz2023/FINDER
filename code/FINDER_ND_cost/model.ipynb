{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c30bd80-f6f4-4b4a-a7ed-3ff1fea24c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farazkhoshbakhtian/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import time\n",
    "import pickle as cp\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import PrepareBatchGraph\n",
    "import graph\n",
    "import nstep_replay_mem\n",
    "import nstep_replay_mem_prioritized\n",
    "import mvc_env\n",
    "import utils\n",
    "import heapq\n",
    "import scipy.linalg as linalg\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9628accf-f8a6-4f73-9c2a-2e20d42d7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FINDER_torch import FINDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28a2397-ade7-46f9-8827-8cee026a0e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CUDA:', False)\n"
     ]
    }
   ],
   "source": [
    "dqn = FINDER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29dbc782-72bb-4217-a988-be12d0021474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generating validation graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|█████████████████████████████████████████████████████████████████████████████████| 200/200 [00:16<00:00, 11.99it/s]"
=======
      "100%|███████████████████████████████████████████████████████████████████████████████████| 200/200 [00:10<00:00, 19.20it/s]"
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Validation of HDA: 0.4692749383022061\n",
      "Validation of HBA: 0.4503116147363310\n",
=======
      "Validation of HDA: 0.4680187079082043\n",
      "Validation of HBA: 0.4491250417937027\n",
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
      "\n",
      "generating new training graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
<<<<<<< HEAD
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 977.56it/s]\n"
=======
      "100%|███████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1533.29it/s]\n",
      "/var/folders/_t/ycs1gv8s5433r_f6cdcw7ny40000gn/T/ipykernel_99143/347219975.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dqn.Train()\n"
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "----From fit: (dense dimensions of input tensors\n"
=======
      "----From fit: (dense dimensions of input tensors\n",
      "('Action Select:', torch.Size([64, 1397]))\n",
      "('rep_global:', torch.Size([0, 0]))\n",
      "('n2nsum_param:', torch.Size([1397, 1397]))\n",
      "('laplacian_param:', torch.Size([1397, 1397]))\n",
      "('subgsum_param:', torch.Size([64, 1397]))\n",
      "('(list) node_input:', 1397)\n",
      "('(list) aux_input:', 64)\n",
      "('(list) target:', 64)\n"
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
     ]
    },
    {
     "ename": "AttributeError",
<<<<<<< HEAD
     "evalue": "'Tensor' object has no attribute 'dense_shape'",
=======
     "evalue": "'FINDER' object has no attribute 'session'",
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
<<<<<<< HEAD
      "\u001b[0;32m/tmp/ipykernel_253/347219975.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/FINDER_new/FINDER-pytorch/code/FINDER_ND_cost/FINDER_torch.pyx\u001b[0m in \u001b[0;36mFINDER_torch.FINDER.Train\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mUPDATE_TIME\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTakeSnapShot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mf_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/FINDER_new/FINDER-pytorch/code/FINDER_ND_cost/FINDER_torch.pyx\u001b[0m in \u001b[0;36mFINDER_torch.FINDER.Fit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_with_prioritized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mISWeights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_at\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_at\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcovered\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/FINDER_new/FINDER-pytorch/code/FINDER_ND_cost/FINDER_torch.pyx\u001b[0m in \u001b[0;36mFINDER_torch.FINDER.fit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetupTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----From fit: (dense dimensions of input tensors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Action Select:\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action_select'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rep_global:\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rep_global'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n2nsum_param:\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n2nsum_param'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'dense_shape'"
=======
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CNDP-RL/FINDER-pytorch/code/FINDER_ND_cost/FINDER_torch.pyx:155\u001b[0m, in \u001b[0;36mFINDER_torch.FINDER.Train\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m     if iter % UPDATE_TIME == 0:\n\u001b[1;32m    154\u001b[0m         self.TakeSnapShot()\n\u001b[0;32m--> 155\u001b[0m     self.Fit()\n\u001b[1;32m    156\u001b[0m f_out.close()\n\u001b[1;32m    157\u001b[0m \n",
      "File \u001b[0;32m~/CNDP-RL/FINDER-pytorch/code/FINDER_ND_cost/FINDER_torch.pyx:417\u001b[0m, in \u001b[0;36mFINDER_torch.FINDER.Fit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    415\u001b[0m         return self.fit_with_prioritized(sample.b_idx,sample.ISWeights,sample.g_list, sample.list_st, sample.list_at,list_target)\n\u001b[1;32m    416\u001b[0m     else:\n\u001b[0;32m--> 417\u001b[0m         return self.fit(sample.g_list, sample.list_st, sample.list_at,list_target)\n\u001b[1;32m    418\u001b[0m \n\u001b[1;32m    419\u001b[0m def fit(self,g_list,covered,actions,list_target):\n",
      "File \u001b[0;32m~/CNDP-RL/FINDER-pytorch/code/FINDER_ND_cost/FINDER_torch.pyx:444\u001b[0m, in \u001b[0;36mFINDER_torch.FINDER.fit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    442\u001b[0m print(\"(list) aux_input:\" , len(self.inputs['aux_input']))\n\u001b[1;32m    443\u001b[0m print(\"(list) target:\" , len(self.inputs['target']))\n\u001b[0;32m--> 444\u001b[0m result = self.session.run([self.loss,self.trainStep],feed_dict={\n\u001b[1;32m    445\u001b[0m                             self.action_select : self.inputs['action_select'],\n\u001b[1;32m    446\u001b[0m                             self.rep_global : self.inputs['rep_global'],\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FINDER' object has no attribute 'session'"
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
     ]
    }
   ],
   "source": [
    "dqn.Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b882ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "rewrited tf to pytorch methods\n",
    "\n",
    "old code is commented out as ref, for example:\n",
    "\n",
    "#y_input_message = tf.matmul(tf.cast(y_node_input,tf.float32), w_n2l)\n",
    "y_input_message = torch.matmul(self.y_node_input.type(torch.FloatTensor), w_n2l)\n",
    "\n",
    "Prepared params such as:\n",
    "y_nodes_size = tf.shape(self.subgsum_param)[0]\n",
    "\n",
    "are kept as-is, since I want to test if this model will run at the end of rewrite functions and layers.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 35,
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
   "id": "a26a1078-8276-4308-9ac7-9d662b4382a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
<<<<<<< HEAD
    "    def __init__(self, embedding_size=64, w_initialization_std=1, reg_hidden=32, max_bp_iter=3, embeddingMethod=1, aux_dim=4,\\\n",
    "                 IsHuberloss=False, IsPrioritizedSampling = False ):\n",
=======
    "    def __init__(self, embedding_size=64, w_initialization_std=1, reg_hidden=32, max_bp_iter=3, embeddingMethod=1, aux_dim=4):\n",
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.rand_generator = torch.normal\n",
    "        self.embedding_size = embedding_size\n",
    "        self.w_initialization_std = w_initialization_std\n",
    "        self.reg_hidden = reg_hidden\n",
    "        self.max_bp_iter = max_bp_iter\n",
    "        self.embeddingMethod = embeddingMethod\n",
    "        self.aux_dim = aux_dim\n",
    "        \n",
<<<<<<< HEAD
    "        self.IsHuberloss = IsHuberloss\n",
    "        self.IsPrioritizedSampling = IsPrioritizedSampling\n",
    "        self.TD_errors = None\n",
    "        #cdef double Alpha = 0.001 ## weight of reconstruction loss\n",
    "        # note there's also an alpha with lower cases\n",
    "        self.Alpha = 0.001\n",
    "        #cdef double LEARNING_RATE = 0.0001   #dai\n",
    "        self.learning_rate = 0.0001\n",
    "        \n",
=======
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        # [2, embed_dim]\n",
    "        self.w_n2l = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                     size=(2, self.embedding_size)), requires_grad=True)\n",
    "        # [embed_dim, embed_dim]\n",
    "        self.p_node_conv = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(self.embedding_size, self.embedding_size)))\n",
    "        \n",
    "        if self.embeddingMethod == 1:    #'graphsage'\n",
    "            # [embed_dim, embed_dim]\n",
    "            self.p_node_conv2 = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(self.embedding_size, self.embedding_size)))\n",
    "            # [2*embed_dim, embed_dim]\n",
    "            self.p_node_conv3 = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(2*self.embedding_size, self.embedding_size)))\n",
    "\n",
    "        #[reg_hidden+aux_dim, 1]\n",
    "        if self.reg_hidden > 0:\n",
    "            # [embed_dim, reg_hidden]\n",
    "            #h1_weight = tf.Variable(tf.truncated_normal([self.embedding_size, self.reg_hidden], stddev=initialization_stddev), tf.float32)\n",
    "            self.h1_weight = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(self.embedding_size, self.reg_hidden)))\n",
    "            \n",
    "            #[reg_hidden+aux_dim, 1]\n",
    "            #h2_weight = tf.Variable(tf.truncated_normal([self.reg_hidden + aux_dim, 1], stddev=initialization_stddev), tf.float32)\n",
    "            self.h2_weight = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(self.reg_hidden + self.aux_dim, 1)))\n",
    "            #[reg_hidden2 + aux_dim, 1]\n",
    "            self.last_w = self.h2_weight\n",
    "        else:\n",
    "            #[2*embed_dim, reg_hidden]\n",
    "            #h1_weight = tf.Variable(tf.truncated_normal([2 * self.embedding_size, self.reg_hidden], stddev=initialization_stddev), tf.float32)\n",
    "            self.h1_weight = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(2*self.embedding_size, self.reg_hidden)))            \n",
    "            #[2*embed_dim, reg_hidden]\n",
    "            self.last_w = h1_weight\n",
    "            \n",
    "        ## [embed_dim, 1]\n",
    "        #cross_product = tf.Variable(tf.truncated_normal([self.embedding_size, 1], stddev=initialization_stddev), tf.float32)\n",
    "        self.cross_product = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(self.embedding_size, 1)))\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "    def train_forward(self, node_input, subgsum_param, n2nsum_param, action_select, aux_input, target, ISWeights):\n",
=======
    "    def train_forward(self, node_input, subgsum_param, n2nsum_param, action_select, aux_input):\n",
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
    "        \n",
    "        y_nodes_size = subgsum_param.shape[0]\n",
    "        # [batch_size, 2]\n",
    "        y_node_input = torch.ones((y_nodes_size,2))\n",
    "\n",
    "        #[node_cnt, 2] * [2, embed_dim] = [node_cnt, embed_dim]\n",
    "        # no sparse\n",
    "        #input_message = tf.matmul(tf.cast(self.node_input,tf.float32), w_n2l)\n",
    "        input_message = torch.matmul(node_input.type(torch.FloatTensor), self.w_n2l)\n",
    "        #[node_cnt, embed_dim]  # no sparse\n",
    "        #input_potential_layer = tf.nn.relu(input_message)\n",
    "        input_potential_layer = self.act(input_message)\n",
    "\n",
    "        # # no sparse\n",
    "        # [batch_size, embed_dim]\n",
    "        #y_input_message = tf.matmul(tf.cast(y_node_input,tf.float32), w_n2l)\n",
    "        y_input_message = torch.matmul(y_node_input.type(torch.FloatTensor), self.w_n2l)\n",
    "        #[batch_size, embed_dim]  # no sparse\n",
    "        #y_input_potential_layer = tf.nn.relu(y_input_message)\n",
    "        y_input_potential_layer = self.act(y_input_message)\n",
    "\n",
    "        #input_potential_layer = input_message\n",
    "        lv = 0\n",
    "        #[node_cnt, embed_dim], no sparse\n",
    "        cur_message_layer = input_potential_layer\n",
    "        #cur_message_layer = tf.nn.l2_normalize(cur_message_layer, axis=1)\n",
    "        cur_message_layer = torch.nn.functional.normalize(cur_message_layer, p=2, dim=1)\n",
    "\n",
    "        #[batch_size, embed_dim], no sparse\n",
    "        y_cur_message_layer = y_input_potential_layer\n",
    "        # [batch_size, embed_dim]\n",
    "        #y_cur_message_layer = tf.nn.l2_normalize(y_cur_message_layer, axis=1)\n",
    "        y_cur_message_layer = torch.nn.functional.normalize(y_cur_message_layer, p=2, dim=1)\n",
    "\n",
    "        # max_bp_iter=3  \n",
    "        while lv < self.max_bp_iter:\n",
    "            lv = lv + 1\n",
    "            #[node_cnt, node_cnt] * [node_cnt, embed_dim] = [node_cnt, embed_dim], dense\n",
    "            #n2npool = tf.sparse_tensor_dense_matmul(tf.cast(self.n2nsum_param,tf.float32), cur_message_layer)\n",
    "            # see https://discuss.pytorch.org/t/sparse-tensors-in-pytorch/859/4\n",
    "            n2npool = torch.matmul(n2nsum_param.type(torch.FloatTensor), cur_message_layer)\n",
    "            #[node_cnt, embed_dim] * [embed_dim, embed_dim] = [node_cnt, embed_dim], dense\n",
    "            #node_linear = tf.matmul(n2npool, p_node_conv)\n",
    "            node_linear = torch.matmul(n2npool, self.p_node_conv)\n",
    "\n",
    "            # [batch_size, node_cnt] * [node_cnt, embed_dim] = [batch_size, embed_dim]\n",
    "            #y_n2npool = tf.sparse_tensor_dense_matmul(tf.cast(self.subgsum_param,tf.float32), cur_message_layer)\n",
    "            # why cur_message_layer, instead of y_cur_message_layer?\n",
    "            y_n2npool = torch.matmul(subgsum_param.type(torch.FloatTensor), cur_message_layer)\n",
    "            #[batch_size, embed_dim] * [embed_dim, embed_dim] = [batch_size, embed_dim], dense\n",
    "            #y_node_linear = tf.matmul(y_n2npool, p_node_conv)\n",
    "            y_node_linear = torch.matmul(y_n2npool, self.p_node_conv)\n",
    "\n",
    "            if self.embeddingMethod == 0: # 'structure2vec'\n",
    "                #[node_cnt, embed_dim] + [node_cnt, embed_dim] = [node_cnt, embed_dim], return tensed matrix\n",
    "                #merged_linear = tf.add(node_linear,input_message)\n",
    "                merged_linear = torch.add(node_linear,input_message)\n",
    "                #[node_cnt, embed_dim]\n",
    "                #cur_message_layer = tf.nn.relu(merged_linear)\n",
    "                cur_message_layer = self.act(merged_linear)\n",
    "\n",
    "                #[batch_size, embed_dim] + [batch_size, embed_dim] = [batch_size, embed_dim], return tensed matrix\n",
    "                #y_merged_linear = tf.add(y_node_linear, y_input_message)\n",
    "                y_merged_linear = torch.add(y_node_linear, y_input_message)\n",
    "                #[batch_size, embed_dim]\n",
    "                #y_cur_message_layer = tf.nn.relu(y_merged_linear)\n",
    "                y_cur_message_layer = self.act(y_merged_linear)\n",
    "                \n",
    "            else:   # 'graphsage'\n",
    "                #[node_cnt, embed_dim] * [embed_dim, embed_dim] = [node_cnt, embed_dim], dense\n",
    "                #cur_message_layer_linear = tf.matmul(tf.cast(cur_message_layer, tf.float32), p_node_conv2)\n",
    "                cur_message_layer_linear = torch.matmul(cur_message_layer.type(torch.FloatTensor), self.p_node_conv2)\n",
    "                #[[node_cnt, embed_dim] [node_cnt, embed_dim]] = [node_cnt, 2*embed_dim], return tensed matrix\n",
    "                #merged_linear = tf.concat([node_linear, cur_message_layer_linear], 1)\n",
    "                merged_linear = torch.concat([node_linear, cur_message_layer_linear], 1)\n",
    "                #[node_cnt, 2*embed_dim]*[2*embed_dim, embed_dim] = [node_cnt, embed_dim]\n",
    "                #cur_message_layer = tf.nn.relu(tf.matmul(merged_linear, p_node_conv3))\n",
    "                cur_message_layer = self.act(torch.matmul(merged_linear, self.p_node_conv3))\n",
    "\n",
    "                #[batch_size, embed_dim] * [embed_dim, embed_dim] = [batch_size, embed_dim], dense\n",
    "                #y_cur_message_layer_linear = tf.matmul(tf.cast(y_cur_message_layer, tf.float32), p_node_conv2)\n",
    "                y_cur_message_layer_linear = torch.matmul(y_cur_message_layer.type(torch.FloatTensor), self.p_node_conv2)\n",
    "                #[[batch_size, embed_dim] [batch_size, embed_dim]] = [batch_size, 2*embed_dim], return tensed matrix\n",
    "                #y_merged_linear = tf.concat([y_node_linear, y_cur_message_layer_linear], 1)\n",
    "                y_merged_linear = torch.concat([y_node_linear, y_cur_message_layer_linear], 1)\n",
    "                #[batch_size, 2*embed_dim]*[2*embed_dim, embed_dim] = [batch_size, embed_dim]\n",
    "                #y_cur_message_layer = tf.nn.relu(tf.matmul(y_merged_linear, p_node_conv3))\n",
    "                y_cur_message_layer = self.act(torch.matmul(y_merged_linear, self.p_node_conv3))\n",
    "\n",
    "            #cur_message_layer = tf.nn.l2_normalize(cur_message_layer, axis=1)\n",
    "            #y_cur_message_layer = tf.nn.l2_normalize(y_cur_message_layer, axis=1)\n",
    "            cur_message_layer = torch.nn.functional.normalize(cur_message_layer, p=2, dim=1)\n",
    "            y_cur_message_layer = torch.nn.functional.normalize(y_cur_message_layer, p=2, dim=1)\n",
    "\n",
    "        \n",
    "        node_embedding = cur_message_layer\n",
    "        #[batch_size, node_cnt] * [node_cnt, embed_dim] = [batch_size, embed_dim], dense\n",
    "        y_potential = y_cur_message_layer\n",
    "        #[batch_size, node_cnt] * [node_cnt, embed_dim] = [batch_size, embed_dim]\n",
    "        #action_embed = tf.sparse_tensor_dense_matmul(tf.cast(self.action_select, tf.float32), cur_message_layer)\n",
    "        action_embed = torch.matmul(action_select.type(torch.FloatTensor), cur_message_layer)\n",
    "\n",
    "        # # [batch_size, embed_dim, embed_dim]\n",
    "        #temp = tf.matmul(tf.expand_dims(action_embed, axis=2),tf.expand_dims(y_potential, axis=1))\n",
    "        temp = torch.matmul(torch.unsqueeze(action_embed, dim=2),torch.unsqueeze(y_potential, dim=1))\n",
    "        # [batch_size, embed_dim]\n",
    "        #Shape = tf.shape(action_embed)\n",
    "        Shape = action_embed.size()\n",
    "        # [batch_size, embed_dim], first transform\n",
    "        #embed_s_a = tf.reshape(tf.matmul(temp, tf.reshape(tf.tile(cross_product,[Shape[0],1]),[Shape[0],Shape[1],1])),Shape)\n",
    "        embed_s_a = torch.reshape(torch.matmul(temp, torch.reshape(torch.tile(self.cross_product,[Shape[0],1]),\\\n",
    "                                                                   [Shape[0],Shape[1],1])),Shape)\n",
    "\n",
    "        #[batch_size, 2 * embed_dim]\n",
    "        last_output = embed_s_a\n",
    "\n",
    "        if self.reg_hidden > 0:\n",
    "            #[batch_size, 2*embed_dim] * [2*embed_dim, reg_hidden] = [batch_size, reg_hidden], dense\n",
    "            #hidden = tf.matmul(embed_s_a, h1_weight)\n",
    "            hidden = torch.matmul(embed_s_a, self.h1_weight)\n",
    "            #[batch_size, reg_hidden]\n",
    "            #last_output = tf.nn.relu(hidden)\n",
    "            last_output = self.act(hidden)\n",
    "\n",
    "        # if reg_hidden == 0: ,[[batch_size, 2*embed_dim], [batch_size, aux_dim]] = [batch_size, 2*embed_dim+aux_dim]\n",
    "        # if reg_hidden > 0: ,[[batch_size, reg_hidden], [batch_size, aux_dim]] = [batch_size, reg_hidden+aux_dim]\n",
    "        #last_output = tf.concat([last_output, self.aux_input], 1)\n",
    "        last_output = torch.concat([last_output, aux_input], 1)\n",
    "        #if reg_hidden == 0: ,[batch_size, 2*embed_dim+aux_dim] * [2*embed_dim+aux_dim, 1] = [batch_size, 1]\n",
    "        #if reg_hidden > 0: ,[batch_size, reg_hidden+aux_dim] * [reg_hidden+aux_dim, 1] = [batch_size, 1]\n",
    "        #q_pred = tf.matmul(last_output, last_w)\n",
    "        q_pred = torch.matmul(last_output, self.last_w)\n",
    "        \n",
<<<<<<< HEAD
=======
    "        ## first order reconstruction loss\n",
    "        #loss_recons = 2 * torch.trace(torch.matmul(torch.transpose(cur_message_layer), torch.matmul(laplacian_param.type(torch.FloatTensor), cur_message_layer)))\n",
    "        #edge_num =  torch.sparse.sum(self.n2nsum_param)\n",
    "        #loss_recons = tf.divide(loss_recons, edge_num)\n",
    "\n",
    "\n",
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
    "        # TODO, losses and more\n",
    "        ## first order reconstruction loss\n",
    "        #loss_recons = 2 * tf.trace(tf.matmul(tf.transpose(cur_message_layer), tf.sparse_tensor_dense_matmul(tf.cast(self.laplacian_param,tf.float32), cur_message_layer)))\n",
    "        loss_recons = 2 * torch.trace(torch.matmul(torch.transpose(cur_message_layer), \\\n",
    "                                                   torch.matmul(laplacian_param.type(torch.FloatTensor), cur_message_layer)))\n",
    "        # Should run on all sparse dim, instead of all dim\n",
    "        # https://machinelearningmastery.com/sparse-matrices-for-machine-learning/\n",
    "        # Test this out first, if values do not match the original\n",
    "        # May need to convert those params to torch.sparse https://pytorch.org/docs/stable/sparse.html\n",
    "        # https://pytorch.org/docs/stable/generated/torch.sparse.sum.html\n",
    "        #edge_num = tf.sparse_reduce_sum(n2nsum_param)\n",
    "        edge_num =  torch.sparse.sum(n2nsum_param)\n",
    "        #loss_recons = tf.divide(loss_recons, edge_num)\n",
    "        loss_recons = torch.divide(loss_recons, edge_num)\n",
    "\n",
    "        if self.IsPrioritizedSampling:\n",
    "            #self.TD_errors = tf.reduce_sum(tf.abs(self.target - q_pred), axis=1)    # for updating Sumtree\n",
    "            self.TD_errors = torch.sum(torch.abs(target - q_pred), axis=1)    # for updating Sumtree\n",
    "            if self.IsHuberloss:\n",
    "                #loss_rl = tf.losses.huber_loss(self.ISWeights * self.target, self.ISWeights * q_pred)\n",
    "                loss_rl = torch.nn.HuberLoss(ISWeights * target, ISWeights * q_pred)\n",
    "            else:\n",
    "                # This could be a bit different because of numerical instabilities, \n",
    "                # but since we are not using IsPrioritized yet, do this for now\n",
    "                #loss_rl = torch.mean(self.ISWeights * tf.squared_difference(self.target, q_pred))\n",
    "                loss_rl = torch.mean(ISWeights * ( (q_pred - self.target) ** 2))\n",
    "        else:\n",
    "            if self.IsHuberloss:\n",
    "                #loss_rl = tf.losses.huber_loss(self.target, q_pred)\n",
    "                loss_rl = torch.nn.HuberLoss(target, q_pred)\n",
    "            else:\n",
    "                #loss_rl = tf.losses.mean_squared_error(self.target, q_pred)\n",
    "                loss_rl = torch.nn.MSELoss(self.target, q_pred)\n",
    "\n",
    "        loss = loss_rl + Alpha * loss_recons\n",
    "        #\n",
    "        # loss = loss_rl\n",
    "\n",
    "        # self.lossRecons = loss_recons\n",
    "        # self.lossRL = loss_rl\n",
    "\n",
    "        # train will be done outside\n",
    "        # trainStep = tf.train.AdamOptimizer(self.learning_rate).minimize(loss)\n",
    "\n",
    "        #[node_cnt, batch_size] * [batch_size, embed_dim] = [node_cnt, embed_dim]\n",
    "        #rep_y = tf.sparse_tensor_dense_matmul(tf.cast(self.rep_global, tf.float32), y_potential       \n",
    "        rep_y = torch.matmul(rep_global.type(torch.FloatTensor), y_potential)\n",
    "        #[[node_cnt, embed_dim], [node_cnt, embed_dim]] = [node_cnt, 2*embed_dim]\n",
    "        # embed_s_a_all = tf.concat([cur_message_layer,rep_y],1)\n",
    "        # # [node_cnt, embed_dim, embed_dim]\n",
    "        #temp1 = tf.matmul(tf.expand_dims(cur_message_layer, axis=2),tf.expand_dims(rep_y, axis=1))\n",
    "        temp1 = torch.matmul(torch.unsqueeze(cur_message_layer, dim=2),torch.unsqueeze(rep_y, dim=1))\n",
    "        # [node_cnt embed_dim]\n",
    "        #Shape1 = tf.shape(cur_message_layer)\n",
    "        Shape1 = cur_message_layer.size()\n",
    "        # [batch_size, embed_dim], first transform\n",
    "        #embed_s_a_all = tf.reshape(tf.matmul(temp1, tf.reshape(tf.tile(cross_product,[Shape1[0],1]),[Shape1[0],Shape1[1],1])),Shape1)\n",
    "        embed_s_a_all = torch.reshape(torch.matmul(temp, torch.reshape(torch.tile(cross_product,[Shape[0],1]),\\\n",
    "                                                                   [Shape[0],Shape[1],1])),Shape1)\n",
    "        \n",
<<<<<<< HEAD
    "        #[node_cnt, 2 * embed_dim]\n",
    "        last_output = embed_s_a_all\n",
    "        if self.reg_hidden > 0:\n",
    "            #[node_cnt, 2 * embed_dim] * [2 * embed_dim, reg_hidden] = [node_cnt, reg_hidden1]\n",
    "            #hidden = tf.matmul(embed_s_a_all, h1_weight)\n",
    "            hidden = torch.matmul(embed_s_a_all, h1_weight)\n",
    "            #Relu, [node_cnt, reg_hidden1]\n",
    "            #last_output = tf.nn.relu(hidden)\n",
    "            last_output = self.act(hidden)\n",
    "            #[node_cnt, reg_hidden1] * [reg_hidden1, reg_hidden2] = [node_cnt, reg_hidden2]\n",
    "            # last_output_hidden = tf.matmul(last_output1, h2_weight)\n",
    "            # last_output = tf.nn.relu(last_output_hidden)\n",
    "\n",
    "        #[node_cnt, batch_size] * [batch_size, aux_dim] = [node_cnt, aux_dim]\n",
    "        #rep_aux = tf.sparse_tensor_dense_matmul(tf.cast(self.rep_global, tf.float32), self.aux_input)\n",
    "        rep_aux = torch.matmul(rep_global.type(torch.FloatTensor), self.aux_input)\n",
    "\n",
    "        #if reg_hidden == 0: , [[node_cnt, 2 * embed_dim], [node_cnt, aux_dim]] = [node_cnt, 2*embed_dim + aux_dim]\n",
    "        #if reg_hidden > 0: , [[node_cnt, reg_hidden], [node_cnt, aux_dim]] = [node_cnt, reg_hidden + aux_dim]\n",
    "        #last_output = tf.concat([last_output,rep_aux],1)\n",
    "        last_output = torch.concat([last_output,rep_aux],1)\n",
    "\n",
    "        #if reg_hidden == 0: , [node_cnt, 2 * embed_dim + aux_dim] * [2 * embed_dim + aux_dim, 1] = [node_cnt，1]\n",
    "        #f reg_hidden > 0: , [node_cnt, reg_hidden + aux_dim] * [reg_hidden + aux_dim, 1] = [node_cnt，1]\n",
    "        q_on_all = torch.matmul(last_output, last_w)\n",
    "       \n",
    " \n",
    "        #return q_pred, cur_message_layer\n",
    "        return loss,q_pred,q_on_all\n",
=======
    "        return q_pred, cur_message_layer\n",
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
    "    \n",
    "    def test_forward(self, node_input, subgsum_param, n2nsum_param, rep_global, aux_input):\n",
    "        \n",
    "        y_nodes_size = subgsum_param.shape[0]\n",
    "        # [batch_size, 2]\n",
    "        y_node_input = torch.ones((y_nodes_size,2))\n",
    "\n",
    "        #[node_cnt, 2] * [2, embed_dim] = [node_cnt, embed_dim]\n",
    "        # no sparse\n",
    "        #input_message = tf.matmul(tf.cast(self.node_input,tf.float32), w_n2l)\n",
    "        input_message = torch.matmul(node_input.type(torch.FloatTensor), self.w_n2l)\n",
    "        #[node_cnt, embed_dim]  # no sparse\n",
    "        #input_potential_layer = tf.nn.relu(input_message)\n",
    "        input_potential_layer = self.act(input_message)\n",
    "\n",
    "        # # no sparse\n",
    "        # [batch_size, embed_dim]\n",
    "        #y_input_message = tf.matmul(tf.cast(y_node_input,tf.float32), w_n2l)\n",
    "        y_input_message = torch.matmul(y_node_input.type(torch.FloatTensor), self.w_n2l)\n",
    "        #[batch_size, embed_dim]  # no sparse\n",
    "        #y_input_potential_layer = tf.nn.relu(y_input_message)\n",
    "        y_input_potential_layer = self.act(y_input_message)\n",
    "\n",
    "        #input_potential_layer = input_message\n",
    "        lv = 0\n",
    "        #[node_cnt, embed_dim], no sparse\n",
    "        cur_message_layer = input_potential_layer\n",
    "        #cur_message_layer = tf.nn.l2_normalize(cur_message_layer, axis=1)\n",
    "        cur_message_layer = torch.nn.functional.normalize(cur_message_layer, p=2, dim=1)\n",
    "\n",
    "        #[batch_size, embed_dim], no sparse\n",
    "        y_cur_message_layer = y_input_potential_layer\n",
    "        # [batch_size, embed_dim]\n",
    "        #y_cur_message_layer = tf.nn.l2_normalize(y_cur_message_layer, axis=1)\n",
    "        y_cur_message_layer = torch.nn.functional.normalize(y_cur_message_layer, p=2, dim=1)\n",
    "\n",
    "        # max_bp_iter=3  \n",
    "        while lv < self.max_bp_iter:\n",
    "            lv = lv + 1\n",
    "            #[node_cnt, node_cnt] * [node_cnt, embed_dim] = [node_cnt, embed_dim], dense\n",
    "            #n2npool = tf.sparse_tensor_dense_matmul(tf.cast(self.n2nsum_param,tf.float32), cur_message_layer)\n",
    "            # see https://discuss.pytorch.org/t/sparse-tensors-in-pytorch/859/4\n",
    "            n2npool = torch.matmul(n2nsum_param.type(torch.FloatTensor), cur_message_layer)\n",
    "            #[node_cnt, embed_dim] * [embed_dim, embed_dim] = [node_cnt, embed_dim], dense\n",
    "            #node_linear = tf.matmul(n2npool, p_node_conv)\n",
    "            node_linear = torch.matmul(n2npool, self.p_node_conv)\n",
    "\n",
    "            # [batch_size, node_cnt] * [node_cnt, embed_dim] = [batch_size, embed_dim]\n",
    "            #y_n2npool = tf.sparse_tensor_dense_matmul(tf.cast(self.subgsum_param,tf.float32), cur_message_layer)\n",
    "            # why cur_message_layer, instead of y_cur_message_layer?\n",
    "            y_n2npool = torch.matmul(subgsum_param.type(torch.FloatTensor), cur_message_layer)\n",
    "            #[batch_size, embed_dim] * [embed_dim, embed_dim] = [batch_size, embed_dim], dense\n",
    "            #y_node_linear = tf.matmul(y_n2npool, p_node_conv)\n",
    "            y_node_linear = torch.matmul(y_n2npool, self.p_node_conv)\n",
    "\n",
    "            if self.embeddingMethod == 0: # 'structure2vec'\n",
    "                #[node_cnt, embed_dim] + [node_cnt, embed_dim] = [node_cnt, embed_dim], return tensed matrix\n",
    "                #merged_linear = tf.add(node_linear,input_message)\n",
    "                merged_linear = torch.add(node_linear,input_message)\n",
    "                #[node_cnt, embed_dim]\n",
    "                #cur_message_layer = tf.nn.relu(merged_linear)\n",
    "                cur_message_layer = self.act(merged_linear)\n",
    "\n",
    "                #[batch_size, embed_dim] + [batch_size, embed_dim] = [batch_size, embed_dim], return tensed matrix\n",
    "                #y_merged_linear = tf.add(y_node_linear, y_input_message)\n",
    "                y_merged_linear = torch.add(y_node_linear, y_input_message)\n",
    "                #[batch_size, embed_dim]\n",
    "                #y_cur_message_layer = tf.nn.relu(y_merged_linear)\n",
    "                y_cur_message_layer = self.act(y_merged_linear)\n",
    "                \n",
    "            else:   # 'graphsage'\n",
    "                #[node_cnt, embed_dim] * [embed_dim, embed_dim] = [node_cnt, embed_dim], dense\n",
    "                #cur_message_layer_linear = tf.matmul(tf.cast(cur_message_layer, tf.float32), p_node_conv2)\n",
    "                cur_message_layer_linear = torch.matmul(cur_message_layer.type(torch.FloatTensor), self.p_node_conv2)\n",
    "                #[[node_cnt, embed_dim] [node_cnt, embed_dim]] = [node_cnt, 2*embed_dim], return tensed matrix\n",
    "                #merged_linear = tf.concat([node_linear, cur_message_layer_linear], 1)\n",
    "                merged_linear = torch.concat([node_linear, cur_message_layer_linear], 1)\n",
    "                #[node_cnt, 2*embed_dim]*[2*embed_dim, embed_dim] = [node_cnt, embed_dim]\n",
    "                #cur_message_layer = tf.nn.relu(tf.matmul(merged_linear, p_node_conv3))\n",
    "                cur_message_layer = self.act(torch.matmul(merged_linear, self.p_node_conv3))\n",
    "\n",
    "                #[batch_size, embed_dim] * [embed_dim, embed_dim] = [batch_size, embed_dim], dense\n",
    "                #y_cur_message_layer_linear = tf.matmul(tf.cast(y_cur_message_layer, tf.float32), p_node_conv2)\n",
    "                y_cur_message_layer_linear = torch.matmul(y_cur_message_layer.type(torch.FloatTensor), self.p_node_conv2)\n",
    "                #[[batch_size, embed_dim] [batch_size, embed_dim]] = [batch_size, 2*embed_dim], return tensed matrix\n",
    "                #y_merged_linear = tf.concat([y_node_linear, y_cur_message_layer_linear], 1)\n",
    "                y_merged_linear = torch.concat([y_node_linear, y_cur_message_layer_linear], 1)\n",
    "                #[batch_size, 2*embed_dim]*[2*embed_dim, embed_dim] = [batch_size, embed_dim]\n",
    "                #y_cur_message_layer = tf.nn.relu(tf.matmul(y_merged_linear, p_node_conv3))\n",
    "                y_cur_message_layer = self.act(torch.matmul(y_merged_linear, self.p_node_conv3))\n",
    "\n",
    "            #cur_message_layer = tf.nn.l2_normalize(cur_message_layer, axis=1)\n",
    "            #y_cur_message_layer = tf.nn.l2_normalize(y_cur_message_layer, axis=1)\n",
    "            cur_message_layer = torch.nn.functional.normalize(cur_message_layer, p=2, dim=1)\n",
    "            y_cur_message_layer = torch.nn.functional.normalize(y_cur_message_layer, p=2, dim=1)\n",
    "\n",
    "        \n",
    "            y_potential = y_cur_message_layer        #[node_cnt, batch_size] * [batch_size, embed_dim] = [node_cnt, embed_dim]\n",
    "        \n",
    "        rep_y = torch.matmul(rep_global.type(torch.FloatTensor), y_potential)\n",
    "        #[[node_cnt, embed_dim], [node_cnt, embed_dim]] = [node_cnt, 2*embed_dim]\n",
    "        # embed_s_a_all = tf.concat([cur_message_layer,rep_y],1)\n",
    "        # # [node_cnt, embed_dim, embed_dim]\n",
    "        temp1 = torch.matmul(torch.unsqueeze(cur_message_layer, dim=2),torch.unsqueeze(rep_y, dim=1))\n",
    "        # [node_cnt embed_dim]\n",
    "        Shape1 = cur_message_layer.size()\n",
    "        # [batch_size, embed_dim], first transform\n",
    "        embed_s_a_all = torch.reshape(torch.matmul(temp1, torch.reshape(torch.tile(self.cross_product,[Shape1[0],1]),[Shape1[0],Shape1[1],1])),Shape1)\n",
    "\n",
    "        #[node_cnt, 2 * embed_dim]\n",
    "        last_output = embed_s_a_all\n",
    "        if self.reg_hidden > 0:\n",
    "            #[node_cnt, 2 * embed_dim] * [2 * embed_dim, reg_hidden] = [node_cnt, reg_hidden1]\n",
    "            hidden = torch.matmul(embed_s_a_all, self.h1_weight)\n",
    "            #Relu, [node_cnt, reg_hidden1]\n",
    "            last_output = self.act(hidden)\n",
    "            #[node_cnt, reg_hidden1] * [reg_hidden1, reg_hidden2] = [node_cnt, reg_hidden2]\n",
    "            # last_output_hidden = tf.matmul(last_output1, h2_weight)\n",
    "            # last_output = tf.nn.relu(last_output_hidden)\n",
<<<<<<< HEAD
    "\n",
    "        #[node_cnt, batch_size] * [batch_size, aux_dim] = [node_cnt, aux_dim]\n",
    "        rep_aux = torch.matmul(rep_global.type(torch.FloatTensor), aux_input)\n",
    "\n",
    "        #if reg_hidden == 0: , [[node_cnt, 2 * embed_dim], [node_cnt, aux_dim]] = [node_cnt, 2*embed_dim + aux_dim]\n",
    "        #if reg_hidden > 0: , [[node_cnt, reg_hidden], [node_cnt, aux_dim]] = [node_cnt, reg_hidden + aux_dim]\n",
    "        last_output = torch.concat([last_output,rep_aux],1)\n",
    "\n",
=======
    "\n",
    "        #[node_cnt, batch_size] * [batch_size, aux_dim] = [node_cnt, aux_dim]\n",
    "        rep_aux = torch.matmul(rep_global.type(torch.FloatTensor), aux_input)\n",
    "\n",
    "        #if reg_hidden == 0: , [[node_cnt, 2 * embed_dim], [node_cnt, aux_dim]] = [node_cnt, 2*embed_dim + aux_dim]\n",
    "        #if reg_hidden > 0: , [[node_cnt, reg_hidden], [node_cnt, aux_dim]] = [node_cnt, reg_hidden + aux_dim]\n",
    "        last_output = torch.concat([last_output,rep_aux],1)\n",
    "\n",
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
    "        #if reg_hidden == 0: , [node_cnt, 2 * embed_dim + aux_dim] * [2 * embed_dim + aux_dim, 1] = [node_cnt，1]\n",
    "        #f reg_hidden > 0: , [node_cnt, reg_hidden + aux_dim] * [reg_hidden + aux_dim, 1] = [node_cnt，1]\n",
    "        q_on_all = torch.matmul(last_output, self.last_w)\n",
    "\n",
    "\n",
    "        return q_on_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "540ad963-67c0-46d8-b865-32a26a1e4567",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training loss for later:\n",
    "\n",
    "## first order reconstruction loss\n",
    "#loss_recons = 2 * torch.trace(torch.matmul(torch.transpose(cur_message_layer), torch.matmul(laplacian_param.type(torch.FloatTensor), cur_message_layer)))\n",
    "#edge_num =  torch.sparse.sum(n2nsum_param)\n",
    "#loss_recons = tf.divide(loss_recons, edge_num)\n",
    "\n",
    "'''\n",
    "if self.IsPrioritizedSampling:\n",
    "    self.TD_errors = tf.reduce_sum(tf.abs(self.target - q_pred), axis=1)    # for updating Sumtree\n",
    "    if self.IsHuberloss:\n",
    "        loss_rl = tf.losses.huber_loss(self.ISWeights * self.target, self.ISWeights * q_pred)\n",
    "    else:\n",
    "        loss_rl = tf.reduce_mean(self.ISWeights * tf.squared_difference(self.target, q_pred))\n",
    "else:\n",
    "    if self.IsHuberloss:\n",
    "        loss_rl = tf.losses.huber_loss(self.target, q_pred)\n",
    "    else:\n",
    "        loss_rl = tf.losses.mean_squared_error(self.target, q_pred)\n",
    "\n",
    "loss = loss_rl + Alpha * loss_recons\n",
    "'''\n",
<<<<<<< HEAD
    "i=1\n",
    "\n"
=======
    "i=1"
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 37,
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
   "id": "1d2e95ea-f857-4ac1-a449-eaa60312d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Model()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
   "id": "acbea487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_n2l None torch.Size([2, 64])\n",
      "p_node_conv None torch.Size([64, 64])\n",
      "p_node_conv2 None torch.Size([64, 64])\n",
      "p_node_conv3 None torch.Size([128, 64])\n",
      "h1_weight None torch.Size([64, 32])\n",
      "h2_weight None torch.Size([36, 1])\n",
      "cross_product None torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in M.named_parameters():\n",
    "    print(name, param.grad, param.size())\n",
    "\n",
    "# TODO[0307:1am], break the model into actual layers to enable grad and loss\n",
    "# might need to write up some custom layers"
=======
   "execution_count": 38,
   "id": "4eff2ca7-c70b-45c8-8733-8d7d7ef22de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dqn.inputs['subgsum_param'])"
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "id": "4eff2ca7-c70b-45c8-8733-8d7d7ef22de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dqn.inputs['subgsum_param'])"
=======
   "execution_count": 39,
   "id": "fc300c09-3ef0-4972-9cfb-c7ece3d8072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18660\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in M.parameters())\n",
    "print(pytorch_total_params)"
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "id": "fc300c09-3ef0-4972-9cfb-c7ece3d8072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18660\n"
=======
   "execution_count": 40,
   "id": "82958d72-2f9b-4f7a-95aa-2eab4107d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_t/ycs1gv8s5433r_f6cdcw7ny40000gn/T/ipykernel_99143/1475947402.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  subgsum_param = torch.tensor(dqn.inputs['subgsum_param'])\n",
      "/var/folders/_t/ycs1gv8s5433r_f6cdcw7ny40000gn/T/ipykernel_99143/1475947402.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  n2nsum_param = torch.tensor(dqn.inputs['n2nsum_param'])\n",
      "/var/folders/_t/ycs1gv8s5433r_f6cdcw7ny40000gn/T/ipykernel_99143/1475947402.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  action_select = torch.tensor(dqn.inputs['action_select'])\n",
      "/var/folders/_t/ycs1gv8s5433r_f6cdcw7ny40000gn/T/ipykernel_99143/1475947402.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rep_global = torch.tensor(dqn.inputs['rep_global'])\n"
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "pytorch_total_params = sum(p.numel() for p in M.parameters())\n",
    "print(pytorch_total_params)"
=======
    "node_input = torch.tensor(dqn.inputs['node_input'])\n",
    "subgsum_param = torch.tensor(dqn.inputs['subgsum_param'])\n",
    "n2nsum_param = torch.tensor(dqn.inputs['n2nsum_param'])\n",
    "action_select = torch.tensor(dqn.inputs['action_select'])\n",
    "aux_input = torch.tensor(dqn.inputs['aux_input'])\n",
    "rep_global = torch.tensor(dqn.inputs['rep_global'])"
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "id": "82958d72-2f9b-4f7a-95aa-2eab4107d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ISWeights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_253/3572163421.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mISWeights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ISWeights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'ISWeights'"
     ]
    }
   ],
   "source": [
    "node_input = torch.tensor(dqn.inputs['node_input'])\n",
    "subgsum_param = torch.tensor(dqn.inputs['subgsum_param'])\n",
    "n2nsum_param = torch.tensor(dqn.inputs['n2nsum_param'])\n",
    "action_select = torch.tensor(dqn.inputs['action_select'])\n",
    "aux_input = torch.tensor(dqn.inputs['aux_input'])\n",
    "rep_global = torch.tensor(dqn.inputs['rep_global'])\n",
    "\n",
    "target = torch.tensor(dqn.inputs['target'])\n",
    "if(dqn.IsPrioritizedSampling):\n",
    "    ISWeights = torch.tensor(dqn.inputs['ISWeights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
=======
   "execution_count": 41,
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
   "id": "ecf75baa-23b0-45d6-8f07-9155e0fea0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "torch.Size([1413, 2])\n",
      "torch.Size([64, 1413])\n",
      "torch.Size([1413, 1413])\n",
      "torch.Size([64, 1413])\n",
=======
      "torch.Size([1397, 2])\n",
      "torch.Size([64, 1397])\n",
      "torch.Size([1397, 1397])\n",
      "torch.Size([64, 1397])\n",
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
      "torch.Size([64, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([], size=(2, 0)),\n",
       "       values=tensor([], size=(0,)),\n",
       "       size=(0, 0), nnz=0, dtype=torch.float64, layout=torch.sparse_coo)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 10,
=======
     "execution_count": 41,
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(node_input.shape)\n",
    "print(subgsum_param.shape)\n",
    "print(n2nsum_param.shape)\n",
    "print(action_select.shape)\n",
    "print(aux_input.shape)\n",
    "rep_global"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 42,
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
   "id": "8f6fdcaf-7cb1-42c1-a184-83b38dfa2c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
<<<<<<< HEAD
      "torch.Size([1413, 64])\n"
=======
      "torch.Size([1397, 64])\n"
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
     ]
    }
   ],
   "source": [
    "q_pred, cur_message_layer = M.train_forward(node_input, subgsum_param, n2nsum_param, action_select, aux_input)\n",
    "print(q_pred.shape)\n",
    "print(cur_message_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 43,
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
   "id": "a5d661b6-e304-42ee-9408-d3b19db79433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in actual testing scnario, instead of action_select, the model recives a variable called rep_global\n",
    "temp =torch.transpose(action_select,0,1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 44,
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
   "id": "ee98c5fd-fef3-4ff0-a578-ed858a3559d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "torch.Size([1413, 1])\n"
=======
      "torch.Size([1397, 1])\n"
>>>>>>> cb8b9456bf03d582ce168010ae4cbfbad8adee00
     ]
    }
   ],
   "source": [
    "q_pred_all = M.test_forward(node_input, subgsum_param, n2nsum_param, temp, aux_input)\n",
    "print(q_pred_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c0424ed-25c9-47e3-8e70-13021645a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dqn.nStepReplayMem.Sampling(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f0ec3d1-48a8-43c1-9a8d-23987e665933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nstep_replay_mem.py_ReplaySample at 0x1b3ffeb80c0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e767c9b2-f3b7-4a25-854f-1b07c605efb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c2a5b-3197-4b84-99b9-2226d9855c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93a7ef-cc95-49f7-b653-22265a88a3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ccf5d8-5e60-4621-992b-bf9bc3102707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6c94ad9-d91a-4fea-a6a7-23648b465699",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665d762e-f545-42da-bc7e-2b54cd7a423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a, y_a = torch.ones((100, 2)), torch.ones(100)\n",
    "x_b, y_b = torch.zeros((100, 2)), torch.zeros(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4acd6117-8839-46b0-a5c1-8a1e39ac06fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<ReluBackward0>)\n",
      "3\n",
      "tensor([[0.8910],\n",
      "        [0.8910],\n",
      "        [0.8910],\n",
      "        [0.8910],\n",
      "        [0.8910]], grad_fn=<ReluBackward0>)\n",
      "3\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<ReluBackward0>)\n",
      "3\n",
      "tensor([[0.1697],\n",
      "        [0.1697],\n",
      "        [0.1697],\n",
      "        [0.1697],\n",
      "        [0.1697]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range (4):\n",
    "    \n",
    "    M = Model(1, 1)\n",
    "\n",
    "\n",
    "    numb_parameters = 0\n",
    "    for param in M.parameters():\n",
    "        numb_parameters += np.prod(list(param.shape))\n",
    "    print(numb_parameters)\n",
    "\n",
    "    print(M(torch.ones((5, 2))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e52856-7e80-4c68-b4eb-2d89cab5b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(M.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b17006-b048-43d0-9d6b-8016bee9bd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass, backward pass, and optimize\n",
    "    outputs = M(x_a)\n",
    "    loss = criterion(outputs[:,0], y_a.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass, backward pass, and optimize\n",
    "    outputs = M(x_b)\n",
    "    loss = criterion(outputs[:,0], y_b.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b447cfa-2270-4239-b725-ead641bf652b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M(torch.ones(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4819649d-a2a2-41ce-a509-7894b5bafe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M(torch.zeros(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6004203-a28d-4e2c-b770-a85d6b4aeaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
