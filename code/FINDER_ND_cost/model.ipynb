{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c30bd80-f6f4-4b4a-a7ed-3ff1fea24c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import time\n",
    "import pickle as cp\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import PrepareBatchGraph\n",
    "import graph\n",
    "import nstep_replay_mem\n",
    "import nstep_replay_mem_prioritized\n",
    "import mvc_env\n",
    "import utils\n",
    "import heapq\n",
    "import scipy.linalg as linalg\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b882ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "rewrited tf to pytorch methods\n",
    "\n",
    "old code is commented out as ref, for example:\n",
    "\n",
    "#y_input_message = tf.matmul(tf.cast(y_node_input,tf.float32), w_n2l)\n",
    "y_input_message = torch.matmul(self.y_node_input.type(torch.FloatTensor), w_n2l)\n",
    "\n",
    "Prepared params such as:\n",
    "y_nodes_size = tf.shape(self.subgsum_param)[0]\n",
    "\n",
    "are kept as-is, since I want to test if this model will run at the end of rewrite functions and layers.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a26a1078-8276-4308-9ac7-9d662b4382a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2562620713.py, line 200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_964/2562620713.py\"\u001b[0;36m, line \u001b[0;32m200\u001b[0m\n\u001b[0;31m    return x\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_size, w_initialization_std):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.rand_generator = torch.normal\n",
    "        self.embedding_size = embedding_size\n",
    "        self.w_initialization_std = w_initialization_std\n",
    "        \n",
    "        # [2, embed_dim]\n",
    "        self.w_n2l = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                     size=(2, self.embedding_size)))\n",
    "        # [embed_dim, embed_dim]\n",
    "        self.p_node_conv = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(self.embedding_size, self.embedding_size)))\n",
    "        \n",
    "        if embeddingMethod == 1:    #'graphsage'\n",
    "            # [embed_dim, embed_dim]\n",
    "            self.p_node_conv2 = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(self.embedding_size, self.embedding_size)))\n",
    "            # [2*embed_dim, embed_dim]\n",
    "            self.p_node_conv3 = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(2*self.embedding_size, self.embedding_size)))\n",
    "\n",
    "        #[reg_hidden+aux_dim, 1]\n",
    "        if self.reg_hidden > 0:\n",
    "            # [embed_dim, reg_hidden]\n",
    "            #h1_weight = tf.Variable(tf.truncated_normal([self.embedding_size, self.reg_hidden], stddev=initialization_stddev), tf.float32)\n",
    "            h1_weight = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(self.embedding_size, self.reg_hidden)))\n",
    "            \n",
    "            #[reg_hidden+aux_dim, 1]\n",
    "            #h2_weight = tf.Variable(tf.truncated_normal([self.reg_hidden + aux_dim, 1], stddev=initialization_stddev), tf.float32)\n",
    "            h2_weight = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(self.reg_hidden + aux_dim, 1)))\n",
    "            #[reg_hidden2 + aux_dim, 1]\n",
    "            last_w = h2_weight\n",
    "        else:\n",
    "            #[2*embed_dim, reg_hidden]\n",
    "            #h1_weight = tf.Variable(tf.truncated_normal([2 * self.embedding_size, self.reg_hidden], stddev=initialization_stddev), tf.float32)\n",
    "            h1_weight = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(2*self.embedding_size, self.reg_hidden)))            \n",
    "            #[2*embed_dim, reg_hidden]\n",
    "            last_w = h1_weight\n",
    "            \n",
    "        ## [embed_dim, 1]\n",
    "        #cross_product = tf.Variable(tf.truncated_normal([self.embedding_size, 1], stddev=initialization_stddev), tf.float32)\n",
    "        cross_product = nn.parameter.Parameter(data=self.rand_generator(0, self.w_initialization_std,\\\n",
    "                                                                           size=(self.embedding_size, 1)))\n",
    "\n",
    "\n",
    "    def train_forward(self, node_input):\n",
    "\n",
    "        #x = torch.matmul(node_input, self.w_n2l)\n",
    "        #x = F.relu(x)\n",
    "        \n",
    "        y_nodes_size = tf.shape(self.subgsum_param)[0]\n",
    "        # [batch_size, 2]\n",
    "        #y_node_input = tf.ones((y_nodes_size,2))\n",
    "        y_node_input = np.ones((y_nodes_size,2))\n",
    "\n",
    "        #[node_cnt, 2] * [2, embed_dim] = [node_cnt, embed_dim]\n",
    "        # no sparse\n",
    "        #input_message = tf.matmul(tf.cast(self.node_input,tf.float32), w_n2l)\n",
    "        input_message = torch.matmul(self.node_input.type(torch.FloatTensor), w_n2l)\n",
    "        #[node_cnt, embed_dim]  # no sparse\n",
    "        #input_potential_layer = tf.nn.relu(input_message)\n",
    "        input_potential_layer = F.relu(input_message)\n",
    "\n",
    "        # # no sparse\n",
    "        # [batch_size, embed_dim]\n",
    "        #y_input_message = tf.matmul(tf.cast(y_node_input,tf.float32), w_n2l)\n",
    "        y_input_message = torch.matmul(self.y_node_input.type(torch.FloatTensor), w_n2l)\n",
    "        #[batch_size, embed_dim]  # no sparse\n",
    "        #y_input_potential_layer = tf.nn.relu(y_input_message)\n",
    "        y_input_potential_layer = F.relu(y_input_message)\n",
    "\n",
    "        #input_potential_layer = input_message\n",
    "        lv = 0\n",
    "        #[node_cnt, embed_dim], no sparse\n",
    "        cur_message_layer = input_potential_layer\n",
    "        #cur_message_layer = tf.nn.l2_normalize(cur_message_layer, axis=1)\n",
    "        cur_message_layer = torch.nn.functional.normalize(cur_message_layer, p=2, dim=1)\n",
    "\n",
    "        #[batch_size, embed_dim], no sparse\n",
    "        y_cur_message_layer = y_input_potential_layer\n",
    "        # [batch_size, embed_dim]\n",
    "        #y_cur_message_layer = tf.nn.l2_normalize(y_cur_message_layer, axis=1)\n",
    "        y_cur_message_layer = torch.nn.functional.normalize(y_cur_message_layer, p=2, dim=1)\n",
    "\n",
    "        # max_bp_iter=3  \n",
    "        while lv < max_bp_iter:\n",
    "            lv = lv + 1\n",
    "            #[node_cnt, node_cnt] * [node_cnt, embed_dim] = [node_cnt, embed_dim], dense\n",
    "            #n2npool = tf.sparse_tensor_dense_matmul(tf.cast(self.n2nsum_param,tf.float32), cur_message_layer)\n",
    "            # see https://discuss.pytorch.org/t/sparse-tensors-in-pytorch/859/4\n",
    "            n2npool = torch.matmul(self.n2nsum_param.type(torch.FloatTensor), cur_message_layer)\n",
    "            #[node_cnt, embed_dim] * [embed_dim, embed_dim] = [node_cnt, embed_dim], dense\n",
    "            #node_linear = tf.matmul(n2npool, p_node_conv)\n",
    "            node_linear = torch.matmul(n2npool, p_node_conv)\n",
    "\n",
    "            # [batch_size, node_cnt] * [node_cnt, embed_dim] = [batch_size, embed_dim]\n",
    "            #y_n2npool = tf.sparse_tensor_dense_matmul(tf.cast(self.subgsum_param,tf.float32), cur_message_layer)\n",
    "            # why cur_message_layer, instead of y_cur_message_layer?\n",
    "            y_n2npool = torch.matmul(self.subgsum_param.type(torch.FloatTensor), cur_message_layer)\n",
    "            #[batch_size, embed_dim] * [embed_dim, embed_dim] = [batch_size, embed_dim], dense\n",
    "            #y_node_linear = tf.matmul(y_n2npool, p_node_conv)\n",
    "            y_node_linear = torch.matmul(y_n2npool, p_node_conv)\n",
    "\n",
    "            if embeddingMethod == 0: # 'structure2vec'\n",
    "                #[node_cnt, embed_dim] + [node_cnt, embed_dim] = [node_cnt, embed_dim], return tensed matrix\n",
    "                #merged_linear = tf.add(node_linear,input_message)\n",
    "                merged_linear = torch.add(node_linear,input_message)\n",
    "                #[node_cnt, embed_dim]\n",
    "                #cur_message_layer = tf.nn.relu(merged_linear)\n",
    "                cur_message_layer = F.relu(merged_linear)\n",
    "\n",
    "                #[batch_size, embed_dim] + [batch_size, embed_dim] = [batch_size, embed_dim], return tensed matrix\n",
    "                #y_merged_linear = tf.add(y_node_linear, y_input_message)\n",
    "                y_merged_linear = torch.add(y_node_linear, y_input_message)\n",
    "                #[batch_size, embed_dim]\n",
    "                #y_cur_message_layer = tf.nn.relu(y_merged_linear)\n",
    "                y_cur_message_layer = F.relu(y_merged_linear)\n",
    "                \n",
    "            else:   # 'graphsage'\n",
    "                #[node_cnt, embed_dim] * [embed_dim, embed_dim] = [node_cnt, embed_dim], dense\n",
    "                #cur_message_layer_linear = tf.matmul(tf.cast(cur_message_layer, tf.float32), p_node_conv2)\n",
    "                cur_message_layer_linear = torch.matmul(cur_message_layer.type(torch.FloatTensor), p_node_conv2)\n",
    "                #[[node_cnt, embed_dim] [node_cnt, embed_dim]] = [node_cnt, 2*embed_dim], return tensed matrix\n",
    "                #merged_linear = tf.concat([node_linear, cur_message_layer_linear], 1)\n",
    "                merged_linear = torch.concat([node_linear, cur_message_layer_linear], 1)\n",
    "                #[node_cnt, 2*embed_dim]*[2*embed_dim, embed_dim] = [node_cnt, embed_dim]\n",
    "                #cur_message_layer = tf.nn.relu(tf.matmul(merged_linear, p_node_conv3))\n",
    "                cur_message_layer = F.relu(torch.matmul(merged_linear, p_node_conv3))\n",
    "\n",
    "                #[batch_size, embed_dim] * [embed_dim, embed_dim] = [batch_size, embed_dim], dense\n",
    "                #y_cur_message_layer_linear = tf.matmul(tf.cast(y_cur_message_layer, tf.float32), p_node_conv2)\n",
    "                y_cur_message_layer_linear = torch.matmul(y_cur_message_layer.type(torch.FloatTensor), p_node_conv2)\n",
    "                #[[batch_size, embed_dim] [batch_size, embed_dim]] = [batch_size, 2*embed_dim], return tensed matrix\n",
    "                #y_merged_linear = tf.concat([y_node_linear, y_cur_message_layer_linear], 1)\n",
    "                y_merged_linear = torch.concat([y_node_linear, y_cur_message_layer_linear], 1)\n",
    "                #[batch_size, 2*embed_dim]*[2*embed_dim, embed_dim] = [batch_size, embed_dim]\n",
    "                #y_cur_message_layer = tf.nn.relu(tf.matmul(y_merged_linear, p_node_conv3))\n",
    "                y_cur_message_layer = F.relu(torch.matmul(y_merged_linear, p_node_conv3))\n",
    "\n",
    "            #cur_message_layer = tf.nn.l2_normalize(cur_message_layer, axis=1)\n",
    "            #y_cur_message_layer = tf.nn.l2_normalize(y_cur_message_layer, axis=1)\n",
    "            cur_message_layer = torch.nn.functional.normalize(cur_message_layer, p=2, dim=1)\n",
    "            y_cur_message_layer = torch.nn.functional.normalize(y_cur_message_layer, p=2, dim=1)\n",
    "\n",
    "        \n",
    "        self.node_embedding = cur_message_layer\n",
    "        #[batch_size, node_cnt] * [node_cnt, embed_dim] = [batch_size, embed_dim], dense\n",
    "        y_potential = y_cur_message_layer\n",
    "        #[batch_size, node_cnt] * [node_cnt, embed_dim] = [batch_size, embed_dim]\n",
    "        #action_embed = tf.sparse_tensor_dense_matmul(tf.cast(self.action_select, tf.float32), cur_message_layer)\n",
    "        action_embed = torch.matmul(self.action_select.type(torch.FloatTensor), cur_message_layer)\n",
    "\n",
    "        # # [batch_size, embed_dim, embed_dim]\n",
    "        #temp = tf.matmul(tf.expand_dims(action_embed, axis=2),tf.expand_dims(y_potential, axis=1))\n",
    "        temp = torch.matmul(torch.unsqueeze(action_embed, dim=2),torch.unsqueeze(y_potential, dim=1))\n",
    "        # [batch_size, embed_dim]\n",
    "        #Shape = tf.shape(action_embed)\n",
    "        Shape = action_embed.size()\n",
    "        # [batch_size, embed_dim], first transform\n",
    "        #embed_s_a = tf.reshape(tf.matmul(temp, tf.reshape(tf.tile(cross_product,[Shape[0],1]),[Shape[0],Shape[1],1])),Shape)\n",
    "        embed_s_a = torch.reshape(torch.matmul(temp, torch.reshape(torch.tile(cross_product,[Shape[0],1]),\\\n",
    "                                                                   [Shape[0],Shape[1],1])),Shape)\n",
    "\n",
    "        #[batch_size, 2 * embed_dim]\n",
    "        last_output = embed_s_a\n",
    "\n",
    "        if self.reg_hidden > 0:\n",
    "            #[batch_size, 2*embed_dim] * [2*embed_dim, reg_hidden] = [batch_size, reg_hidden], dense\n",
    "            #hidden = tf.matmul(embed_s_a, h1_weight)\n",
    "            hidden = torch.matmul(embed_s_a, h1_weight)\n",
    "            #[batch_size, reg_hidden]\n",
    "            #last_output = tf.nn.relu(hidden)\n",
    "            last_output = F.relu(hidden)\n",
    "\n",
    "        # if reg_hidden == 0: ,[[batch_size, 2*embed_dim], [batch_size, aux_dim]] = [batch_size, 2*embed_dim+aux_dim]\n",
    "        # if reg_hidden > 0: ,[[batch_size, reg_hidden], [batch_size, aux_dim]] = [batch_size, reg_hidden+aux_dim]\n",
    "        #last_output = tf.concat([last_output, self.aux_input], 1)\n",
    "        last_output = torch.concat([last_output, self.aux_input], 1)\n",
    "        #if reg_hidden == 0: ,[batch_size, 2*embed_dim+aux_dim] * [2*embed_dim+aux_dim, 1] = [batch_size, 1]\n",
    "        #if reg_hidden > 0: ,[batch_size, reg_hidden+aux_dim] * [reg_hidden+aux_dim, 1] = [batch_size, 1]\n",
    "        #q_pred = tf.matmul(last_output, last_w)\n",
    "        q_pred = torch.matmul(last_output, last_w)\n",
    "\n",
    "        # TODO, losses and more\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def test_forward(self, node_input):\n",
    "\n",
    "        x = torch.matmul(node_input, self.w_n2l)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        if embeddingMethod == 1:    #'graphsage'\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540ad963-67c0-46d8-b865-32a26a1e4567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10709f97-3593-4229-959b-8439d6fab617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e29815-7e8e-4e71-9a11-a795f67529fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e95ea-f857-4ac1-a449-eaa60312d6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035eda07-01d5-40b4-b7d9-dca3ccf5f42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6fdcaf-7cb1-42c1-a184-83b38dfa2c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3899c8-4691-4c22-a629-f83ae0bc5cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf899d-5f5c-4aef-af9f-ef7a394c61a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0424ed-25c9-47e3-8e70-13021645a87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ec3d1-48a8-43c1-9a8d-23987e665933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e767c9b2-f3b7-4a25-854f-1b07c605efb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c2a5b-3197-4b84-99b9-2226d9855c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93a7ef-cc95-49f7-b653-22265a88a3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ccf5d8-5e60-4621-992b-bf9bc3102707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6c94ad9-d91a-4fea-a6a7-23648b465699",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665d762e-f545-42da-bc7e-2b54cd7a423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a, y_a = torch.ones((100, 2)), torch.ones(100)\n",
    "x_b, y_b = torch.zeros((100, 2)), torch.zeros(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4acd6117-8839-46b0-a5c1-8a1e39ac06fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<ReluBackward0>)\n",
      "3\n",
      "tensor([[0.8910],\n",
      "        [0.8910],\n",
      "        [0.8910],\n",
      "        [0.8910],\n",
      "        [0.8910]], grad_fn=<ReluBackward0>)\n",
      "3\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<ReluBackward0>)\n",
      "3\n",
      "tensor([[0.1697],\n",
      "        [0.1697],\n",
      "        [0.1697],\n",
      "        [0.1697],\n",
      "        [0.1697]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range (4):\n",
    "    \n",
    "    M = Model(1, 1)\n",
    "\n",
    "\n",
    "    numb_parameters = 0\n",
    "    for param in M.parameters():\n",
    "        numb_parameters += np.prod(list(param.shape))\n",
    "    print(numb_parameters)\n",
    "\n",
    "    print(M(torch.ones((5, 2))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e52856-7e80-4c68-b4eb-2d89cab5b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(M.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b17006-b048-43d0-9d6b-8016bee9bd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass, backward pass, and optimize\n",
    "    outputs = M(x_a)\n",
    "    loss = criterion(outputs[:,0], y_a.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass, backward pass, and optimize\n",
    "    outputs = M(x_b)\n",
    "    loss = criterion(outputs[:,0], y_b.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b447cfa-2270-4239-b725-ead641bf652b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784],\n",
       "        [3.0784]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M(torch.ones(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4819649d-a2a2-41ce-a509-7894b5bafe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M(torch.zeros(20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6004203-a28d-4e2c-b770-a85d6b4aeaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
